# ğŸ“ é¡¹ç›®ç»“æ„
# nlp-vis-app/
# â”œâ”€â”€ app.py                  # ä¸»å…¥å£ï¼šStreamlit UI + åŠŸèƒ½é€»è¾‘
# â”œâ”€â”€ models/
# â”‚   â””â”€â”€ model_config.json   # å¯é€‰æ¨¡å‹é…ç½®ï¼ˆåç§° -> huggingfaceæ¨¡å‹åï¼‰
# â”œâ”€â”€ data/
# â”‚   â””â”€â”€ sst2_dev.json       # ç¤ºä¾‹æ•°æ®é›†
# â”œâ”€â”€ utils.py                # åŠŸèƒ½å‡½æ•°ï¼ˆåŠ è½½æ¨¡å‹ã€ç»˜å›¾ç­‰ï¼‰
# â””â”€â”€ requirements.txt        # ä¾èµ–

# ğŸ”¹ Step 1: requirements.txtï¼ˆä¾èµ–æ–‡ä»¶ï¼‰
# ------------------------------
# streamlit
# torch
# transformers
# scikit-learn
# matplotlib
# umap-learn
# pandas

# ğŸ”¹ Step 2: models/model_config.json
# ------------------------------
# {
#   "sst2-tiny": "sshleifer/tiny-distilbert-base-uncased-finetuned-sst-2-english",
#   "sst2-base": "distilbert-base-uncased-finetuned-sst-2-english"
# }

# ğŸ”¹ Step 3: data/sst2_dev.jsonï¼ˆç¤ºä¾‹ï¼‰
# ------------------------------
# [
#   {"sentence": "it's a charming and often affecting journey.", "label": 1},
#   {"sentence": "unflinchingly bleak and desperate", "label": 0},
#   {"sentence": "a major career as a commercial yet inventive filmmaker", "label": 1}
# ]

# ğŸ”¹ Step 4: utils.py
# ------------------------------
import torch
import pandas as pd
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from sklearn.manifold import TSNE
import umap
import numpy as np

@torch.no_grad()
def load_model_and_tokenizer(hf_model):
    tokenizer = AutoTokenizer.from_pretrained(hf_model)
    model = AutoModelForSequenceClassification.from_pretrained(hf_model)
    model.eval()
    return tokenizer, model

@torch.no_grad()
def compute_embeddings(texts, tokenizer, model):
    inputs = tokenizer(texts, return_tensors="pt", padding=True, truncation=True)
    outputs = model(**inputs, output_hidden_states=True)
    cls_embeddings = outputs.hidden_states[-1][:, 0, :].numpy()
    reducer = umap.UMAP()
    reduced = reducer.fit_transform(cls_embeddings)
    return reduced


# ğŸ”¹ Step 5: app.pyï¼ˆä¸»å…¥å£ï¼‰
# ------------------------------
import streamlit as st
import json
import pandas as pd
import matplotlib.pyplot as plt
import torch
import numpy as np
from utils import load_model_and_tokenizer, compute_embeddings

# âœ… å°±æ”¾åœ¨è¿™é‡Œ

# ä¸‹é¢æ˜¯ä½ çš„é¡µé¢è®¾ç½®ã€æ¨¡å‹åŠ è½½ç­‰ä»£ç 
st.set_page_config(page_title="NLP å¯è§†åŒ–å¹³å°", layout="wide")
st.title("ğŸŒŸ NLP æ¨¡å‹å¯è§†åŒ–ç³»ç»Ÿ")

# é¡µé¢è®¾ç½®
st.set_page_config("ğŸ§  NLP æ¨¡å‹è§£é‡Šå¹³å°", layout="wide")
st.title("ğŸ§  NLP æ¨¡å‹å¯è§†åŒ–ä¸è§£é‡Šå¹³å° (Lite)")

# æ¨¡å‹é…ç½®
with open("models/model_config.json") as f:
    model_dict = json.load(f)

model_name = st.sidebar.selectbox("é€‰æ‹©æ¨¡å‹", list(model_dict.keys()))
tokenizer, model = load_model_and_tokenizer(model_dict[model_name])

# æ•°æ®åŠ è½½
uploaded_file = st.sidebar.file_uploader("ä¸Šä¼ æ•°æ® (JSON, åŒ…å« sentence å’Œ label å­—æ®µ)", type="json")
if uploaded_file:
    data = pd.read_json(uploaded_file)
else:
    data = pd.read_json("data/sst2_dev.json")

# å¯è§†åŒ–åµŒå…¥ï¼ˆé™ç»´ï¼‰
embeddings = compute_embeddings(data["sentence"].tolist(), tokenizer, model)

# åˆ†ç±»é¢„æµ‹
inputs = tokenizer(data["sentence"].tolist(), return_tensors="pt", padding=True, truncation=True)
outputs = model(**inputs)
probs = torch.nn.functional.softmax(outputs.logits, dim=-1).numpy()
preds = probs.argmax(axis=1)

# ä¸»ç•Œé¢å¸ƒå±€
col1, col2 = st.columns([1, 2])

with col1:
    st.subheader("ğŸ“„ æ•°æ®è¡¨")
    st.dataframe(data)
    selected_idx = st.number_input("é€‰æ‹©ç´¢å¼•ä»¥æŸ¥çœ‹è¯¦ç»†ä¿¡æ¯", min_value=0, max_value=len(data)-1, value=0)

    st.markdown("#### ğŸ§¾ æ¨¡å‹åˆ†ç±»ç»“æœ")
    st.write(f"**Sentence:** {data['sentence'][selected_idx]}")
    st.write(f"**True Label:** {data['label'][selected_idx]}")
    st.write(f"**Predicted:** {preds[selected_idx]} | Confidence: {probs[selected_idx].max():.2f}")

with col2:
    st.subheader("ğŸ“Š åµŒå…¥æŠ•å½±")
    fig, ax = plt.subplots()
    colors = ["blue" if p==1 else "orange" for p in preds]
    ax.scatter(embeddings[:, 0], embeddings[:, 1], c=colors, alpha=0.7)
    ax.scatter(embeddings[selected_idx, 0], embeddings[selected_idx, 1], c="red", s=100, label="Selected")
    ax.legend()
    st.pyplot(fig)

st.markdown("---")
st.caption("ğŸ”— æœ¬é¡µé¢åŸºäº HuggingFace + UMAP + Streamlit æ„å»ºï¼Œæ”¯æŒåµŒå…¥æŠ•å½±ã€åˆ†ç±»è§£é‡Šã€æ–‡æœ¬åˆ†æç­‰åŠŸèƒ½ã€‚")

# ğŸ”š


